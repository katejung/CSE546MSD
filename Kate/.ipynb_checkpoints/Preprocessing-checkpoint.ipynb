{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import datetime\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "from beat_aligned_feats import get_bttimbre\n",
    "import compress_feat as CBTF \n",
    "import randproj as RANDPROJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sw_k_jung/Google Drive/Cloud/CSE546/data_train/C 0\n",
      "/Users/sw_k_jung/Google Drive/Cloud/CSE546/data_train/C/R 0\n",
      "/Users/sw_k_jung/Google Drive/Cloud/CSE546/data_train/C/R/R 0\n"
     ]
    }
   ],
   "source": [
    "# path to the Million Song Dataset subset (uncompressed)\n",
    "msd_subset_path='/Users/sw_k_jung/Google Drive/Cloud/CSE546/Project/'\n",
    "msd_subset_data_path='/Users/sw_k_jung/Google Drive/Cloud/CSE546/data_train/C'\n",
    "msd_subset_addf_path=os.path.join(msd_subset_path,'helpers')\n",
    "msd_code_path='/Users/sw_k_jung/Google Drive/Cloud/CSE546/Project/helpers'\n",
    "sys.path.append(os.path.join(msd_code_path,'PythonSrc') )\n",
    "import hdf5_getters as GETTERS\n",
    "def get_time_warp_matrix(segstart, btstart, duration):\n",
    "    \"\"\"\n",
    "    Used by create_beat_synchro_chromagram\n",
    "    Returns a matrix (#beats,#segs)\n",
    "    #segs should be larger than #beats, i.e. many events or segs\n",
    "    happen in one beat.\n",
    "    THIS FUNCTION WAS ORIGINALLY CREATED BY RON J. WEISS (Columbia/NYU/Google)\n",
    "    \"\"\"\n",
    "    # length of beats and segments in seconds\n",
    "    # result for track: 'TR0002Q11C3FA8332D'\n",
    "    #    seglen.shape = (708,)\n",
    "    #    btlen.shape = (304,)\n",
    "    #    duration = 238.91546    meaning approx. 3min59s\n",
    "    seglen = np.concatenate((segstart[1:], [duration])) - segstart\n",
    "    btlen = np.concatenate((btstart[1:], [duration])) - btstart\n",
    "\n",
    "    warpmat = np.zeros((len(segstart), len(btstart)))\n",
    "    # iterate over beats (columns of warpmat)\n",
    "    for n in range(len(btstart)):\n",
    "        # beat start time and end time in seconds\n",
    "        start = btstart[n]\n",
    "        end = start + btlen[n]\n",
    "        # np.nonzero returns index of nonzero elems\n",
    "        # find first segment that starts after beat starts - 1\n",
    "        try:\n",
    "            start_idx = np.nonzero((segstart - start) >= 0)[0][0] - 1\n",
    "        except IndexError:\n",
    "            # no segment start after that beats, can happen close\n",
    "            # to the end, simply ignore, maybe even break?\n",
    "            # (catching faster than ckecking... it happens rarely?)\n",
    "            break\n",
    "        # find first segment that starts after beat ends\n",
    "        segs_after = np.nonzero((segstart - end) >= 0)[0]\n",
    "        if segs_after.shape[0] == 0:\n",
    "            end_idx = start_idx\n",
    "        else:\n",
    "            end_idx = segs_after[0]\n",
    "        # fill col of warpmat with 1 for the elem in between\n",
    "        # (including start_idx, excluding end_idx)\n",
    "        warpmat[start_idx:end_idx, n] = 1.\n",
    "        # if the beat started after the segment, keep the proportion\n",
    "        # of the segment that is inside the beat\n",
    "        warpmat[start_idx, n] = 1. - ((start - segstart[start_idx])\n",
    "                                 / seglen[start_idx])\n",
    "        # if the segment ended after the beat ended, keep the proportion\n",
    "        # of the segment that is inside the beat\n",
    "        if end_idx - 1 > start_idx:\n",
    "            warpmat[end_idx-1, n] = ((end - segstart[end_idx-1])\n",
    "                                     / seglen[end_idx-1])\n",
    "        # normalize so the 'energy' for one beat is one\n",
    "        warpmat[:, n] /= np.sum(warpmat[:, n])\n",
    "        return warpmat.T\n",
    "    # return the transpo\n",
    "def get_bttatums(h5):\n",
    "    tatums = GETTERS.get_tatums_start(h5)\n",
    "    segstarts = GETTERS.get_segments_start(h5)\n",
    "    btstarts = GETTERS.get_beats_start(h5)\n",
    "    duration = GETTERS.get_duration(h5)\n",
    "    btstarts = np.array(btstarts).flatten()\n",
    "    numbt = btstarts.shape[0]\n",
    "    bttatums = np.zeros(numbt)\n",
    "    i,j = 0,0\n",
    "    while i < len(tatums):\n",
    "        while j < len(btstarts) and btstarts[j] < tatums[i] :\n",
    "            j+=1\n",
    "        if j < len(btstarts):\n",
    "            bttatums[j] +=1 \n",
    "        i += 1\n",
    "    if bttatums is None:\n",
    "        return None\n",
    "    return np.array([bttatums])\n",
    "\n",
    "def getSamples(basedir):\n",
    "    X, Y = [],[]\n",
    "    feature_labels = ['segments_pitch', \n",
    "                 'segments_timbre',\n",
    "                 'segments_loudness_max',\n",
    "                 'tempo']\n",
    "    cnt = 0\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*.h5'))\n",
    "        print(root, cnt)\n",
    "        # apply function to all files\n",
    "        for f in files :\n",
    "#             try:\n",
    "            h5 = GETTERS.open_h5_file_read(f)\n",
    "#                 segments_pitch = GETTERS.get_segments_pitches(h5)\n",
    "#                 segments_timbre = GETTERS.get_segments_timbre(h5)\n",
    "#                 segments_loudness_max = GETTERS.get_segments_loudness_max(h5)\n",
    "#                 tempo = GETTERS.get_tempo(h5)\n",
    "#             except:\n",
    "#                 h5.close()\n",
    "#                 print('error')\n",
    "#                 continue\n",
    "            year = GETTERS.get_year(h5)\n",
    "            time_sig = GETTERS.get_time_signature(h5)\n",
    "            if year == 0:\n",
    "                continue\n",
    "            bttimbre = get_bttimbre(h5)\n",
    "            bttatums = get_bttatums(h5)\n",
    "            h5.close()\n",
    "            if bttimbre is None or bttatums is None or year == 0:\n",
    "                continue\n",
    "            X.append([bttimbre,bttatums,time_sig])\n",
    "            Y.append(year)\n",
    "            cnt+=1\n",
    "            if cnt  > 1000:\n",
    "                break;\n",
    "    return X, Y, feature_labels\n",
    "\n",
    "X, Y, labels = getSamples(msd_subset_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X), len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "# Generate a normal distribution, center at x=0 and y=5\n",
    "\n",
    "X_filtered = []\n",
    "Y_filtered = []\n",
    "decades= dict()\n",
    "for i, year in enumerate(Y):\n",
    "    if year >= 1940:\n",
    "        decade = year-(year%10)\n",
    "        X_filtered.append(X[i])\n",
    "        Y_filtered.append(Y[i])\n",
    "        if decade not in decades:\n",
    "            decades[decade] = 1\n",
    "        else:\n",
    "            decades[decade] +=1\n",
    "print(len(X_filtered),len(Y_filtered))\n",
    "print(decades)\n",
    "plt.hist(Y_filtered, bins=50)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def extract_and_compress(btfeat, npicks, winsize, finaldim, seed=3232343, randproj=None):\n",
    "    \"\"\"\n",
    "    From a btfeat matrix, usually 12xLENGTH\n",
    "    Extracts 'npicks' windows of size 'winsize' equally spaced\n",
    "    Flatten these picks, pass them through a random projection, final\n",
    "    size is 'finaldim'\n",
    "    Returns matrix npicks x finaldim, or 0 x finaldim if problem\n",
    "    (btfeats not long enough for instance)\n",
    "    We could return less than npicks if not long enough!\n",
    "    For speed, we can compute the random projection once and pass it as an\n",
    "    argument.\n",
    "    \"\"\"\n",
    "    # features length\n",
    "    ftlen = btfeat.shape[1]\n",
    "    ndim = btfeat.shape[0]\n",
    "    # too small case\n",
    "    if ftlen < winsize:\n",
    "        return np.zeros((0, finaldim))\n",
    "    # random projection\n",
    "    if randproj is None:\n",
    "        randproj = RANDPROJ.proj_point5(ndim * winsize, finaldim, seed=seed)\n",
    "    # not big enough for number of picks, last one too large return just 1\n",
    "    if ftlen < int(ftlen * (npicks * 1. / (npicks + 1))) + winsize:\n",
    "        pos = int((ftlen - winsize) / 2.)  # middle\n",
    "        picks = [btfeat[:, pos:pos + winsize]]\n",
    "    # regular case, picks will contain npicks\n",
    "    else:\n",
    "        picks = []\n",
    "        for k in range(1, npicks + 1):\n",
    "            pos = int(ftlen * (k * 1. / (npicks + 1)))\n",
    "            picks.append(btfeat[:, pos:pos + winsize])\n",
    "\n",
    "    # # project / compress these\n",
    "    projections = list(map(lambda x: np.dot(x.flatten(), randproj).reshape(1, finaldim), picks))\n",
    "    return np.concatenate(projections)\n",
    "\n",
    "def flatten(X,Y, npicks = 3, winsize = 12, finaldim = 5):\n",
    "    flattenedX,flattenedY = [],[]\n",
    "    for i in range(len(X)):\n",
    "#     for i in range(1):\n",
    "        x = X[i]\n",
    "        bttimbre = x[0]\n",
    "        bttatums = x[1] # ndarray 1 x numbt \n",
    "        time_sig = x[2]\n",
    "        ndim_timbre = bttimbre.shape[0]\n",
    "        ndim_tatum = bttatums.shape[0]\n",
    "        numbt = bttatums.shape[1]\n",
    "\n",
    "        if time_sig is not None:\n",
    "            winsize = time_sig\n",
    "            npicks = int(numbt/winsize)\n",
    "        randproj_timbre = RANDPROJ.proj_point5(ndim_timbre * winsize, finaldim)\n",
    "        randproj_tatum = RANDPROJ.proj_point5(ndim_tatum * winsize, finaldim)\n",
    "        if numbt > npicks:\n",
    "            processed_timbre = extract_and_compress(bttimbre,npicks,winsize,finaldim,randproj=randproj_timbre)\n",
    "            processed_tatum = extract_and_compress(bttatums,npicks,winsize,finaldim,randproj=randproj_tatum)\n",
    "            processed_feats = []\n",
    "            for n in range(processed_tatum.shape[0]):\n",
    "                processed_feats.append(np.concatenate((processed_timbre[n], processed_tatum[n]), axis=None))\n",
    "            flattenedX =flattenedX+processed_feats\n",
    "            flattenedY = flattenedY+processed_tatum.shape[0]*[Y[i]]\n",
    "    return flattenedX, flattenedY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import linear_model\n",
    "error1, error2 = [], []\n",
    "for finaldim in range(1, 100,10):\n",
    "    print(finaldim)\n",
    "    X_flattened,Y_flattened = flatten(X_filtered, Y_filtered, finaldim=finaldim) \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_flattened, Y_flattened, test_size=0.2, random_state=42)\n",
    "    print('train num', len(y_train), 'test num', len(y_test))\n",
    "\n",
    "    regr =linear_model.LinearRegression()\n",
    "    regr.fit(X_train,y_train)\n",
    "    regr_predict = regr.predict(X_test)\n",
    "    error  = np.mean(np.abs(y_test - regr_predict))\n",
    "    error1.append(error)\n",
    "    print('linear model', error, np.mean(regr_predict) ,np.std(reg_predict))\n",
    "\n",
    "    error_list,squared_list = [],[]\n",
    "    knn = KNeighborsClassifier(n_neighbors=50)\n",
    "    knn.fit(X_train, y_train)\n",
    "    predicted_years = knn.predict(X_test)\n",
    "    error  = np.mean(np.abs(y_test - predicted_years))\n",
    "    error2.append(error)\n",
    "    print('50 knn', error, np.mean(predicted_years),np.std(predicted_years))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(error_list))\n",
    "print(len(squared_list))\n",
    "\n",
    "line1 = plt.plot(arange(1, 100,10), error_list, label = 'Linear Model')\n",
    "line2 = plt.plot(arange(1, 100,10), squared_list, label= '50-knn')\n",
    "plt.legend()\n",
    "plt.xlabel('final dimension')\n",
    "plt.ylabel('Year diff')\n",
    "plt.title(r'Average Year Difference')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(13,13,13),max_iter=1000)\n",
    "mlp.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_predicted_year = mlp.predict(X_test)\n",
    "error_mlp = np.sum(np.abs(predicted_years - y_test))/n_test\n",
    "squared_mlp = np.sqrt(np.sum(np.abs((predicted_years - y_test)**2))/n_test)\n",
    "print(error_mlp, squared_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
